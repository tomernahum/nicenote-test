


TODO Next:
- Crypto
- batching

TODO:
- clean up the console logs
- ask AI for tips on code quality, api design


TODO Later:
- fix up snapshotting to be more intelligent, don't make duplicate snapshots, don't make them too frequently, maybe notify clients of new snapshots to help with them deciding whether to snapshot (may fix the above on its own)

- publish this in it's own repo
- publish this on npm

- abstract the buckets for dynamic amount of buckets (should be easy right?)

- write up what is and isn't in the threat model / accomplished by this system. And what can be toggled

--
Mitigations:
- batching for timing side channel

Remaining problems
- need mitigation for server disrupting integrity by omitting subset of updates
    - eg tie updates to creator, tie that to user identity, then soft block that one user
- (may not solve): server knows who made an update based on ip address, may know more about identity
    - maybe p2p / websockets will help with this?
--
Some notes:
rowId is also stored along side the sealedMessage in plain text (not encrypted or verified...)
todo is that bad? 
    threats (cia):
    - DoS from server (don't care about in our model currently)
    - spying from server (most important)
    - fake data / integrity from server (do care about)
        server can not fabricate updates or transactions
        but with no verification of rowIds, it could reorder updates/transactions
            this does not change the end state though if we are using mutable operations like from CRDTs/yjs
        it can also omit certain updates
            this would change the end state!!
            but server can't distinguish updates to know which updates to omit
                except from the side channel of message size & message timing/frequency
                    & who the update came from (eg ip address) (big one)
                also it could just want to cause chaos by showing different users different subsets of updates
            solution?: embed order in messages and don't show updates without having the previous one
                but messages may be sent at the same time from different devices...
                I think there could be some way to do this though 
                could also do partial solution like enforcing order per each device
        for now I will not solve this but hope to later. 
            Also idk if using websockets would solve this automatically since server only sets up direct connection between two clients. Actually it wouldn't 100% unless we use pure gossip protocol, which would not work for our desired ux of everything showing up, since updates need to be stored somewhere so server has to be involved. we could redundantly gossip, and then ask server for all or just remaining updates, that way server will have a harder time with it. 
            All these solutions require a bunch of work for a relatively unlikely-to-happen seeming problem
            will maybe implement them only after a product with this library takes off
        above reordering problem exists regardless of rowid
        the other threat is it would trick clients into telling it to delete incorrect updates as part of snapshot (or just delete the wrong ones regardless). I think that is the same problem as above?



-----Oldish---------


- intelligent snapshot rejection on server?

- notify clients of new snapshots?
    - waste of bandwidth if snapshots are really correct
- periodic reloads of doc just in case it diverges
    - related to above
    - balance of bandwidth usage vs safety
- only send snapshot if document is too long including snapshots?
    - need to notify client of existence of new snapshots for this (not necessarily send the whole content down...)


- proper cryptography key stuff.
    - support multiple keys & while-running key rotation
    - write keys
maybe: writer id or writer key id recorded in operation. later may add custom resolving crdt-like which takes this into account
    for now plan was to have one shared write-key. we could give each writer their own key per document = almost same as identity 

- error handling down to user (eg max server message size)
- clean up console logs

- deploy for easier cross-device testing


- batching of updates to mask frequency of them from server






- server: think about spam prevention story maybe? & integration with a proper authed / customized extendible server (besides cryptography auth)
    - maybe turn backend into library or something idk

- is there a way to replace server with webrtc + storage endpoint for more decentralization/openness, but more importantly to save on egress charges?
    is ingress of storage of new updates free? , and only loading the doc (maybe even only while noone else is online) has to be egress

- make sure it is as bug free as possible

- restructure folders and stuff

- publish this

Maybe:
- delete/wipe doc functionality? (you can just squash empty doc in prod and delete from sql viewer in dev though)
- maybe deprecate connect to doc flow in 2-server-interface, since we want to fetch it before connecting to socket part
- or not. it's possible I got confused thinking that http is faster than spinning up websocket.

later: make buckets dynamic
& add other crdt libraries / custom (loro tree & reducer-based)

--


Make sure everything is good

--
- could abstract bucket from "doc"|"awareness" to be any string, to more easily connect to other crdts or even ordered reducers